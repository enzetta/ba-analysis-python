{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8431e4d",
   "metadata": {},
   "source": [
    "# Hypothesis 3 Testing\n",
    "Testing toxicity differences between parties in terms of sent and received toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "743b32e2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Data handling and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "\n",
    "# BigQuery\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.exceptions import GoogleCloudError\n",
    "\n",
    "# Set up environment\n",
    "import os\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/Users/zetta/projects/twitter-analysis-python/.secrets/service-account.json'\n",
    "\n",
    "# Initialize BigQuery client\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Output directory setup\n",
    "OUTPUT_DIR = \"outputs\"\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d46b9c54",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_query(query, use_cache=True):\n",
    "    \"\"\"Execute a BigQuery query and return results as a DataFrame.\"\"\"\n",
    "    try:\n",
    "        job_config = bigquery.QueryJobConfig(use_query_cache=use_cache)\n",
    "        query_job = client.query(query, job_config=job_config)\n",
    "        results_df = query_job.to_dataframe(create_bqstorage_client=False)\n",
    "        print(f\"Query executed successfully. Retrieved {len(results_df)} rows.\")\n",
    "        return results_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query: {str(e)}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf75680",
   "metadata": {},
   "source": [
    "## 1. Data Collection\n",
    "Fetch toxicity data by party"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ade8857",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully. Retrieved 168 rows.\n"
     ]
    }
   ],
   "source": [
    "# Query to get toxicity data by party\n",
    "query = \"\"\"\n",
    "WITH party_mapping AS (\n",
    "    SELECT party,\n",
    "    CASE\n",
    "        WHEN party = 'CDU' THEN 'cdu'\n",
    "        WHEN party = 'SPD' THEN 'spdde'\n",
    "        WHEN party = 'CSU' THEN 'csu'\n",
    "        WHEN party = 'FDP' THEN 'fdp'\n",
    "        WHEN party = 'Bündnis 90/Die Grünen' THEN 'die_gruenen'\n",
    "        WHEN party = 'DIE LINKE' THEN 'dielinke'\n",
    "        WHEN party = 'AfD' THEN 'afd'\n",
    "    END AS party_id,\n",
    "    CAST(avg_tox_sent AS FLOAT64) as avg_tox_sent,\n",
    "    CAST(avg_tox_received AS FLOAT64) as avg_tox_received\n",
    "FROM `grounded-nebula-408412.twitter_analysis_30_stats.toxcity_by_party`\n",
    "WHERE party IN ('CDU', 'SPD', 'CSU', 'FDP', 'Bündnis 90/Die Grünen', 'DIE LINKE', 'AfD')\n",
    ")\n",
    "SELECT \n",
    "    party_id as party,\n",
    "    avg_tox_sent,\n",
    "    avg_tox_received\n",
    "FROM party_mapping\n",
    "WHERE avg_tox_sent IS NOT NULL\n",
    "  AND avg_tox_received IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "party_data = run_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2291b05c",
   "metadata": {},
   "source": [
    "## 2. Kruskal-Wallis Test\n",
    "Testing whether there are significant differences in toxicity between parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11626924",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kruskal-Wallis Test Results:\n",
      "             Metric  H-statistic       p-value  Significant\n",
      "0      avg_tox_sent    63.088898  1.058653e-11         True\n",
      "0  avg_tox_received    76.361651  2.012232e-14         True\n"
     ]
    }
   ],
   "source": [
    "def perform_kruskal_wallis(df, metric):\n",
    "    \"\"\"Perform Kruskal-Wallis test for a given toxicity metric.\"\"\"\n",
    "    # Filter out NaN values\n",
    "    df = df.dropna(subset=[metric])\n",
    "    if len(df) == 0:\n",
    "        return pd.DataFrame({\n",
    "            'Metric': [metric],\n",
    "            'H-statistic': [np.nan],\n",
    "            'p-value': [np.nan],\n",
    "            'Significant': [False]\n",
    "        })\n",
    "    \n",
    "    groups = [group[metric].values for name, group in df.groupby('party')]\n",
    "    if len(groups) < 2:\n",
    "        return pd.DataFrame({\n",
    "            'Metric': [metric],\n",
    "            'H-statistic': [np.nan],\n",
    "            'p-value': [np.nan],\n",
    "            'Significant': [False]\n",
    "        })\n",
    "    \n",
    "    h_stat, p_val = stats.kruskal(*groups)\n",
    "    return pd.DataFrame({\n",
    "        'Metric': [metric],\n",
    "        'H-statistic': [h_stat],\n",
    "        'p-value': [p_val],\n",
    "        'Significant': [p_val < 0.05]\n",
    "    })\n",
    "\n",
    "# Run tests for toxicity metrics\n",
    "metrics = ['avg_tox_sent', 'avg_tox_received']\n",
    "kw_results = pd.concat([perform_kruskal_wallis(party_data, metric) for metric in metrics])\n",
    "\n",
    "print(\"\\nKruskal-Wallis Test Results:\")\n",
    "print(kw_results)\n",
    "\n",
    "# Save results\n",
    "timestamp = pd.Timestamp.now().strftime('%Y%m%d')\n",
    "kw_results.to_csv(os.path.join(OUTPUT_DIR, f'h3_kruskal_wallis_{timestamp}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92beb506",
   "metadata": {},
   "source": [
    "## 3. Mann-Whitney U Test\n",
    "Testing pairwise differences in toxicity between parties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "027008d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mann-Whitney U Test Results for avg_tox_sent:\n",
      "\n",
      "Significant differences found between:\n",
      "afd vs die_gruenen:\n",
      "  U-statistic: 573.0000\n",
      "  p-value: 4.4565e-09\n",
      "  Effect Size: 0.8467\n",
      "afd vs cdu:\n",
      "  U-statistic: 574.0000\n",
      "  p-value: 3.9348e-09\n",
      "  Effect Size: 0.8497\n",
      "afd vs csu:\n",
      "  U-statistic: 570.0000\n",
      "  p-value: 6.4584e-09\n",
      "  Effect Size: 0.8378\n",
      "afd vs dielinke:\n",
      "  U-statistic: 576.0000\n",
      "  p-value: 3.0637e-09\n",
      "  Effect Size: 0.8557\n",
      "afd vs fdp:\n",
      "  U-statistic: 576.0000\n",
      "  p-value: 3.0637e-09\n",
      "  Effect Size: 0.8557\n",
      "afd vs spdde:\n",
      "  U-statistic: 575.0000\n",
      "  p-value: 3.4727e-09\n",
      "  Effect Size: 0.8527\n",
      "\n",
      "Mann-Whitney U Test Results for avg_tox_received:\n",
      "\n",
      "Significant differences found between:\n",
      "afd vs die_gruenen:\n",
      "  U-statistic: 561.0000\n",
      "  p-value: 1.9223e-08\n",
      "  Effect Size: 0.8110\n",
      "afd vs cdu:\n",
      "  U-statistic: 562.0000\n",
      "  p-value: 1.7057e-08\n",
      "  Effect Size: 0.8140\n",
      "afd vs csu:\n",
      "  U-statistic: 564.0000\n",
      "  p-value: 1.3413e-08\n",
      "  Effect Size: 0.8199\n",
      "afd vs dielinke:\n",
      "  U-statistic: 510.0000\n",
      "  p-value: 4.9416e-06\n",
      "  Effect Size: 0.6592\n",
      "afd vs fdp:\n",
      "  U-statistic: 576.0000\n",
      "  p-value: 3.0637e-09\n",
      "  Effect Size: 0.8557\n",
      "afd vs spdde:\n",
      "  U-statistic: 496.0000\n",
      "  p-value: 1.8809e-05\n",
      "  Effect Size: 0.6176\n",
      "die_gruenen vs dielinke:\n",
      "  U-statistic: 156.0000\n",
      "  p-value: 6.6983e-03\n",
      "  Effect Size: 0.3914\n",
      "die_gruenen vs fdp:\n",
      "  U-statistic: 442.0000\n",
      "  p-value: 1.5502e-03\n",
      "  Effect Size: 0.4568\n",
      "die_gruenen vs spdde:\n",
      "  U-statistic: 177.0000\n",
      "  p-value: 2.2698e-02\n",
      "  Effect Size: 0.3289\n",
      "cdu vs fdp:\n",
      "  U-statistic: 468.0000\n",
      "  p-value: 2.1456e-04\n",
      "  Effect Size: 0.5342\n",
      "csu vs dielinke:\n",
      "  U-statistic: 184.0000\n",
      "  p-value: 3.2832e-02\n",
      "  Effect Size: 0.3080\n",
      "csu vs fdp:\n",
      "  U-statistic: 448.0000\n",
      "  p-value: 1.0060e-03\n",
      "  Effect Size: 0.4747\n",
      "dielinke vs fdp:\n",
      "  U-statistic: 512.0000\n",
      "  p-value: 4.0560e-06\n",
      "  Effect Size: 0.6652\n",
      "fdp vs spdde:\n",
      "  U-statistic: 77.0000\n",
      "  p-value: 1.4220e-05\n",
      "  Effect Size: 0.6265\n",
      "\n",
      "Descriptive Statistics by Party:\n",
      "            avg_tox_sent                         avg_tox_received          \\\n",
      "                   count    mean  median     std            count    mean   \n",
      "party                                                                       \n",
      "afd                   24  0.1759  0.1761  0.0310               24  0.2441   \n",
      "cdu                   24  0.0683  0.0625  0.0338               24  0.1291   \n",
      "csu                   24  0.0652  0.0610  0.0352               24  0.1234   \n",
      "die_gruenen           24  0.0690  0.0521  0.0322               24  0.1196   \n",
      "dielinke              24  0.0694  0.0639  0.0165               24  0.1565   \n",
      "fdp                   24  0.0600  0.0500  0.0299               24  0.0826   \n",
      "spdde                 24  0.0618  0.0563  0.0256               24  0.1551   \n",
      "\n",
      "                             \n",
      "             median     std  \n",
      "party                        \n",
      "afd          0.2352  0.0446  \n",
      "cdu          0.1280  0.0416  \n",
      "csu          0.1158  0.0457  \n",
      "die_gruenen  0.1056  0.0406  \n",
      "dielinke     0.1403  0.0538  \n",
      "fdp          0.0727  0.0317  \n",
      "spdde        0.1401  0.0608  \n"
     ]
    }
   ],
   "source": [
    "def perform_mann_whitney_tests(df, metric):\n",
    "    \"\"\"\n",
    "    Perform Mann-Whitney U tests between all pairs of parties for a given metric.\n",
    "    \"\"\"\n",
    "    parties = df['party'].unique()\n",
    "    results = []\n",
    "    \n",
    "    for i, party1 in enumerate(parties):\n",
    "        for party2 in parties[i+1:]:\n",
    "            group1 = df[df['party'] == party1][metric]\n",
    "            group2 = df[df['party'] == party2][metric]\n",
    "            \n",
    "            # Perform Mann-Whitney U test\n",
    "            u_stat, p_val = stats.mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "            \n",
    "            # Calculate effect size (r = Z / sqrt(N))\n",
    "            n1, n2 = len(group1), len(group2)\n",
    "            z_score = stats.norm.ppf(p_val / 2)\n",
    "            effect_size = abs(z_score) / np.sqrt(n1 + n2)\n",
    "            \n",
    "            results.append({\n",
    "                'Party 1': party1,\n",
    "                'Party 2': party2,\n",
    "                'Metric': metric,\n",
    "                'U-statistic': u_stat,\n",
    "                'p-value': p_val,\n",
    "                'Effect Size': effect_size,\n",
    "                'Significant': p_val < 0.05\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run Mann-Whitney U tests for both toxicity metrics\n",
    "all_mw_results = []\n",
    "\n",
    "for metric in metrics:\n",
    "    mw_results = perform_mann_whitney_tests(party_data, metric)\n",
    "    all_mw_results.append(mw_results)\n",
    "    \n",
    "    print(f\"\\nMann-Whitney U Test Results for {metric}:\")\n",
    "    significant_results = mw_results[mw_results['Significant']]\n",
    "    if len(significant_results) > 0:\n",
    "        print(\"\\nSignificant differences found between:\")\n",
    "        for _, row in significant_results.iterrows():\n",
    "            print(f\"{row['Party 1']} vs {row['Party 2']}:\")\n",
    "            print(f\"  U-statistic: {row['U-statistic']:.4f}\")\n",
    "            print(f\"  p-value: {row['p-value']:.4e}\")\n",
    "            print(f\"  Effect Size: {row['Effect Size']:.4f}\")\n",
    "    else:\n",
    "        print(\"No significant differences found between any parties.\")\n",
    "\n",
    "# Save results\n",
    "for i, metric in enumerate(metrics):\n",
    "    results_df = all_mw_results[i]\n",
    "    results_df.to_csv(os.path.join(OUTPUT_DIR, f'h3_mann_whitney_{metric}_{timestamp}.csv'), index=False)\n",
    "\n",
    "# Calculate descriptive statistics by party\n",
    "desc_stats = party_data.groupby('party').agg({\n",
    "    'avg_tox_sent': ['count', 'mean', 'median', 'std'],\n",
    "    'avg_tox_received': ['count', 'mean', 'median', 'std']\n",
    "}).round(4)\n",
    "\n",
    "print(\"\\nDescriptive Statistics by Party:\")\n",
    "print(desc_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a0ff35",
   "metadata": {},
   "source": [
    "## 4. Visualization of Mann-Whitney U Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "126e58d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def create_mann_whitney_heatmap(mw_results, metric, party_names):\n",
    "    \"\"\"Create a heatmap visualization for Mann-Whitney U test results.\"\"\"\n",
    "    # Get unique parties\n",
    "    parties = sorted(set(mw_results['Party 1'].unique()) | set(mw_results['Party 2'].unique()))\n",
    "    n_parties = len(parties)\n",
    "    \n",
    "    # Create matrices for heatmap and annotations\n",
    "    heatmap_matrix = np.zeros((n_parties, n_parties))\n",
    "    annot_matrix = np.empty((n_parties, n_parties), dtype=object)\n",
    "    \n",
    "    # Initialize matrices with empty strings\n",
    "    for i in range(n_parties):\n",
    "        for j in range(n_parties):\n",
    "            annot_matrix[i, j] = ''\n",
    "    \n",
    "    # Fill matrices with values\n",
    "    for _, row in mw_results.iterrows():\n",
    "        i = parties.index(row['Party 1'])\n",
    "        j = parties.index(row['Party 2'])\n",
    "        \n",
    "        # Format p-value with asterisks for significance\n",
    "        sig_str = '***' if row['p-value'] < 0.001 else ('**' if row['p-value'] < 0.01 else ('*' if row['p-value'] < 0.05 else ''))\n",
    "        \n",
    "        # Format statistics\n",
    "        if row['Significant']:\n",
    "            stats_str = f\"U={row['U-statistic']:.0f}\\np={row['p-value']:.4f}{sig_str}\\nr={row['Effect Size']:.2f}\"\n",
    "            \n",
    "            # Store values in both positions of the matrix\n",
    "            heatmap_matrix[i, j] = row['Effect Size']\n",
    "            heatmap_matrix[j, i] = row['Effect Size']\n",
    "            annot_matrix[i, j] = stats_str\n",
    "            annot_matrix[j, i] = stats_str\n",
    "    \n",
    "    # Create mask for upper triangle\n",
    "    mask = np.triu(np.ones_like(heatmap_matrix, dtype=bool))\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Create heatmap\n",
    "    ax = sns.heatmap(heatmap_matrix,\n",
    "                     mask=mask,\n",
    "                     xticklabels=[party_names.get(p, p) for p in parties],\n",
    "                     yticklabels=[party_names.get(p, p) for p in parties],\n",
    "                     cmap='YlOrRd',\n",
    "                     center=0,\n",
    "                     vmin=0,\n",
    "                     vmax=max(mw_results['Effect Size']),\n",
    "                     square=True,\n",
    "                     cbar_kws={'label': 'Effect Size (r)'},\n",
    "                     annot=annot_matrix,\n",
    "                     fmt='',\n",
    "                     annot_kws={'color': 'white', 'fontsize': 11})\n",
    "    \n",
    "    # Rotate x-axis labels\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    # Set title\n",
    "    plt.title(f'Effect Sizes of Significant Differences in {metric}', pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save plot\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, f'mann_whitney_heatmap_{metric}_{timestamp}.png'),\n",
    "                dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Create heatmaps for both metrics\n",
    "PARTY_NAMES = {\n",
    "    \"cdu\": \"CDU\",\n",
    "    \"spdde\": \"SPD\",\n",
    "    \"csu\": \"CSU\",\n",
    "    \"fdp\": \"FDP\",\n",
    "    \"die_gruenen\": \"Die Grünen\",\n",
    "    \"dielinke\": \"Die Linke\",\n",
    "    \"afd\": \"AfD\"\n",
    "}\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    create_mann_whitney_heatmap(all_mw_results[i], metric, PARTY_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e926944f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c54136",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
