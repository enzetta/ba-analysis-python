{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b3482b2",
   "metadata": {},
   "source": [
    "# H1: Network Metrics Correlation Analysis\n",
    "\n",
    "This notebook analyzes correlations between various network metrics from our Twitter dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82f55ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data handling and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import stats\n",
    "\n",
    "# BigQuery\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.exceptions import GoogleCloudError\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# Set up environment\n",
    "import os\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/Users/zetta/projects/twitter-analysis-python/.secrets/service-account.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16c7f8d2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Create BigQuery client\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Output directory setup\n",
    "OUTPUT_DIR = \"outputs\"\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "# Dataset configurations\n",
    "DATASETS = {\n",
    "    'all': {\n",
    "        'table': 'grounded-nebula-408412.twitter_analysis_00_source_python.network_metrics_all',\n",
    "        'name': 'All Topics Network',\n",
    "        'output_prefix': 'all'\n",
    "    },\n",
    "    'climate': {\n",
    "        'table': 'grounded-nebula-408412.twitter_analysis_00_source_python.network_metrics_climate',\n",
    "        'name': 'Climate Network',\n",
    "        'output_prefix': 'climate'\n",
    "    },\n",
    "    'migration': {\n",
    "        'table': 'grounded-nebula-408412.twitter_analysis_00_source_python.network_metrics_migration',\n",
    "        'name': 'Migration Network',\n",
    "        'output_prefix': 'migration'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Plotting configurations\n",
    "PLOT_FIGURE_SIZE = (12, 12 / 16 * 9)\n",
    "PLOT_DPI = 300\n",
    "BASE_FONT_SIZE = 14\n",
    "\n",
    "# Configure plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = PLOT_FIGURE_SIZE\n",
    "plt.rcParams['font.size'] = BASE_FONT_SIZE\n",
    "\n",
    "# Selected metrics for analysis\n",
    "SELECTED_METRICS = [\n",
    "    \"modularity\",\n",
    "    \"network_avg_toxicity\",\n",
    "    \"transitivity\",\n",
    "    \"assortativity\",\n",
    "    \"max_core_number\",\n",
    "    \"rich_club_coefficient\",\n",
    "    \"average_clustering\",\n",
    "    \"connected_components\",\n",
    "    \"density\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4114a349",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define all helper functions\n",
    "def run_query(query, use_cache=True):\n",
    "    \"\"\"Execute a BigQuery query and return results as a DataFrame.\"\"\"\n",
    "    try:\n",
    "        job_config = bigquery.QueryJobConfig(use_query_cache=use_cache)\n",
    "        query_job = client.query(query, job_config=job_config)\n",
    "        results_df = query_job.to_dataframe(create_bqstorage_client=False)\n",
    "        print(f\"Query executed successfully. Retrieved {len(results_df)} rows.\")\n",
    "        return results_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def normalize_series(series):\n",
    "    \"\"\"Normalize a series using z-score normalization.\"\"\"\n",
    "    return (series - series.mean()) / series.std()\n",
    "\n",
    "def format_plot(ax, title=None, xlabel=None, ylabel=None, ylim_start=0, ylim_end=None):\n",
    "    \"\"\"Apply standard formatting to a matplotlib axis.\"\"\"\n",
    "    if title:\n",
    "        ax.set_title(title, fontweight='regular', pad=15, fontsize=BASE_FONT_SIZE + 2)\n",
    "    if xlabel:\n",
    "        ax.set_xlabel(xlabel, fontsize=BASE_FONT_SIZE)\n",
    "    if ylabel:\n",
    "        ax.set_ylabel(ylabel, fontsize=BASE_FONT_SIZE)\n",
    "    if ylim_end is not None:\n",
    "        ax.set_ylim(ylim_start, ylim_end)\n",
    "    elif ylim_start > 0:\n",
    "        ax.set_ylim(bottom=ylim_start)\n",
    "    \n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.5, color=\"#E0E0E0\")\n",
    "    ax.set_axisbelow(True)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6051f4c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define statistical analysis functions\n",
    "def calculate_statistical_measures(df, metrics, normalize=True):\n",
    "    \"\"\"Calculate various statistical measures between metrics.\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for i, metric1 in enumerate(metrics):\n",
    "        results[metric1] = {}\n",
    "        for metric2 in metrics[i + 1:]:\n",
    "            x = df[metric1].values\n",
    "            y = df[metric2].values\n",
    "            \n",
    "            if normalize:\n",
    "                x = normalize_series(pd.Series(x))\n",
    "                y = normalize_series(pd.Series(y))\n",
    "            \n",
    "            pearson_r, pearson_p = stats.pearsonr(x, y)\n",
    "            spearman_r, spearman_p = stats.spearmanr(x, y)\n",
    "            \n",
    "            z = np.polyfit(x, y, 1)\n",
    "            p = np.poly1d(z)\n",
    "            y_pred = p(x)\n",
    "            r_squared = 1 - np.sum((y - y_pred) ** 2) / np.sum((y - y.mean()) ** 2)\n",
    "            \n",
    "            results[metric1][metric2] = {\n",
    "                'pearson_r': pearson_r,\n",
    "                'pearson_p': pearson_p,\n",
    "                'spearman_r': spearman_r,\n",
    "                'spearman_p': spearman_p,\n",
    "                'r_squared': r_squared,\n",
    "                'slope': z[0],\n",
    "                'intercept': z[1]\n",
    "            }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def calculate_lagged_correlations(df, metrics, max_lag=3, normalize=True):\n",
    "    \"\"\"Calculate lagged correlations between selected metrics.\"\"\"\n",
    "    lag_correlations = {}\n",
    "    \n",
    "    for metric1 in metrics:\n",
    "        lag_correlations[metric1] = {}\n",
    "        for metric2 in metrics:\n",
    "            if metric1 != metric2:\n",
    "                lag_correlations[metric1][metric2] = []\n",
    "                for lag in range(max_lag + 1):\n",
    "                    if lag == 0:\n",
    "                        x = df[metric1].values\n",
    "                        y = df[metric2].values\n",
    "                    else:\n",
    "                        x = df[metric1][lag:].values\n",
    "                        y = df[metric2][:-lag].values\n",
    "                    \n",
    "                    if normalize:\n",
    "                        x = normalize_series(pd.Series(x))\n",
    "                        y = normalize_series(pd.Series(y))\n",
    "                    \n",
    "                    z = np.polyfit(x, y, 1)\n",
    "                    p = np.poly1d(z)\n",
    "                    y_pred = p(x)\n",
    "                    r_squared = 1 - np.sum((y - y_pred) ** 2) / np.sum((y - y.mean()) ** 2)\n",
    "                    corr = stats.spearmanr(x, y)[0]\n",
    "                    \n",
    "                    lag_correlations[metric1][metric2].append({\n",
    "                        'lag': lag,\n",
    "                        'correlation': corr,\n",
    "                        'r_squared': r_squared\n",
    "                    })\n",
    "    \n",
    "    return lag_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18ef44cc",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define Kruskal-Wallis test function\n",
    "def perform_kruskal_wallis_test(datasets_data):\n",
    "    \"\"\"\n",
    "    Perform Kruskal-Wallis H-test across different network datasets for each metric.\n",
    "    \n",
    "    Args:\n",
    "        datasets_data (dict): Dictionary containing DataFrames for each dataset\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing test results for each metric\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for metric in SELECTED_METRICS:\n",
    "        # Prepare data for the test\n",
    "        metric_data = [df[metric].dropna() for df in datasets_data.values()]\n",
    "        dataset_names = list(datasets_data.keys())\n",
    "        \n",
    "        # Perform Kruskal-Wallis H-test\n",
    "        h_statistic, p_value = stats.kruskal(*metric_data)\n",
    "        \n",
    "        # Store results\n",
    "        results[metric] = {\n",
    "            'h_statistic': h_statistic,\n",
    "            'p_value': p_value,\n",
    "            'dataset_sizes': [len(data) for data in metric_data],\n",
    "            'dataset_names': dataset_names\n",
    "        }\n",
    "        \n",
    "        # Calculate mean ranks for each group\n",
    "        all_data = np.concatenate(metric_data)\n",
    "        all_ranks = stats.rankdata(all_data)\n",
    "        \n",
    "        current_pos = 0\n",
    "        mean_ranks = []\n",
    "        for data in metric_data:\n",
    "            group_ranks = all_ranks[current_pos:current_pos + len(data)]\n",
    "            mean_ranks.append(np.mean(group_ranks))\n",
    "            current_pos += len(data)\n",
    "            \n",
    "        results[metric]['mean_ranks'] = dict(zip(dataset_names, mean_ranks))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49c1857d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_query_for_dataset(dataset_config):\n",
    "    \"\"\"Execute a BigQuery query for a specific dataset and return results as a DataFrame.\"\"\"\n",
    "    query = f\"\"\"\n",
    "    SELECT \n",
    "        month_start,\n",
    "        nodes,\n",
    "        edges,\n",
    "        density,\n",
    "        connected_components,\n",
    "        transitivity,\n",
    "        modularity,\n",
    "        modularity_classes,\n",
    "        assortativity,\n",
    "        network_avg_toxicity,\n",
    "        median_node_toxicity,\n",
    "        max_core_number,\n",
    "        avg_core_number,\n",
    "        rich_club_coefficient,\n",
    "        average_clustering\n",
    "    FROM `{dataset_config['table']}`\n",
    "    ORDER BY month_start\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        job_config = bigquery.QueryJobConfig(use_query_cache=True)\n",
    "        query_job = client.query(query, job_config=job_config)\n",
    "        results_df = query_job.to_dataframe(create_bqstorage_client=False)\n",
    "        print(f\"Query executed successfully for {dataset_config['name']}. Retrieved {len(results_df)} rows.\")\n",
    "        return results_df\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query for {dataset_config['name']}: {str(e)}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bc66607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully for All Topics Network. Retrieved 24 rows.\n",
      "Query executed successfully for Climate Network. Retrieved 24 rows.\n",
      "Query executed successfully for Migration Network. Retrieved 24 rows.\n"
     ]
    }
   ],
   "source": [
    "# Load data for each dataset\n",
    "datasets_data = {}\n",
    "for dataset_key, dataset_config in DATASETS.items():\n",
    "    df = run_query_for_dataset(dataset_config)\n",
    "    if not df.empty:\n",
    "        datasets_data[dataset_key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3abc7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kruskal-Wallis Test Results:\n",
      "============================\n",
      "               Metric  H-statistic      p-value  Significant  all_mean_rank  climate_mean_rank  migration_mean_rank\n",
      " connected_components    54.577055 1.408456e-12         True      60.500000          16.375000            32.625000\n",
      "   average_clustering    47.461377 4.941887e-11         True      60.500000          23.458333            25.541667\n",
      "         transitivity    46.257420 9.022541e-11         True      59.958333          27.833333            21.708333\n",
      "      max_core_number    44.473981 2.200886e-10         True      59.416667          21.729167            28.354167\n",
      "           modularity    38.859209 3.646113e-09         True      14.833333          45.750000            48.916667\n",
      "rich_club_coefficient    36.719368 1.062895e-08         True      57.625000          26.541667            25.333333\n",
      "              density    29.229642 4.496388e-07         True      24.250000          55.041667            30.208333\n",
      " network_avg_toxicity    14.303843 7.833573e-04         True      23.333333          42.375000            43.791667\n",
      "        assortativity     4.435502 1.088536e-01        False      29.458333          38.208333            41.833333\n"
     ]
    }
   ],
   "source": [
    "# Perform Kruskal-Wallis tests\n",
    "kw_results = perform_kruskal_wallis_test(datasets_data)\n",
    "\n",
    "# Create a summary DataFrame\n",
    "summary_rows = []\n",
    "for metric, result in kw_results.items():\n",
    "    row = {\n",
    "        'Metric': metric,\n",
    "        'H-statistic': result['h_statistic'],\n",
    "        'p-value': result['p_value'],\n",
    "        'Significant': result['p_value'] < 0.05\n",
    "    }\n",
    "    # Add mean ranks for each dataset\n",
    "    for dataset, rank in result['mean_ranks'].items():\n",
    "        row[f'{dataset}_mean_rank'] = rank\n",
    "    summary_rows.append(row)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df = summary_df.sort_values('p-value')\n",
    "\n",
    "# Display results\n",
    "print(\"\\nKruskal-Wallis Test Results:\")\n",
    "print(\"============================\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bef26c81",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Create visualization of results\n",
    "metrics = summary_df['Metric'].tolist()\n",
    "datasets = [col.replace('_mean_rank', '') for col in summary_df.columns if col.endswith('_mean_rank')]\n",
    "rank_data = np.zeros((len(metrics), len(datasets)))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    for j, dataset in enumerate(datasets):\n",
    "        rank_data[i, j] = summary_df.loc[summary_df['Metric'] == metric, f'{dataset}_mean_rank'].values[0]\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(rank_data, \n",
    "            xticklabels=datasets,\n",
    "            yticklabels=metrics,\n",
    "            cmap='YlOrRd',\n",
    "            annot=True,\n",
    "            fmt='.1f')\n",
    "plt.title('Mean Ranks by Dataset and Metric')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'kruskal_wallis_heatmap.png'), dpi=PLOT_DPI, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Save results to CSV\n",
    "summary_df.to_csv(os.path.join(OUTPUT_DIR, 'kruskal_wallis_results.csv'), index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f572742a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840a640b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ced403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5b5b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29e120e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775574c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d1cdd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad9921e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
